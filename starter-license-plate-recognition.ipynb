{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from keras.layers import Dense, Flatten, Input, Conv2D, MaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils import Sequence, plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "files = glob.glob(\"/kaggle/input/synthetic-turkish-license-plates/license-plates/*.png\")\n",
    "all_files = [(os.path.splitext(os.path.basename(file))[0], file) for file in files]\n",
    "\n",
    "X = [filename[1] for filename in all_files]\n",
    "y1 = np.array([plate_label[0].replace(\"-\", \"\")[0] for plate_label in all_files])\n",
    "y2 = np.array([plate_label[0].replace(\"-\", \"\")[1] for plate_label in all_files])\n",
    "y3 = np.array([plate_label[0].replace(\"-\", \"\")[2] for plate_label in all_files])\n",
    "y4 = np.array([plate_label[0].replace(\"-\", \"\")[3] for plate_label in all_files])\n",
    "y5 = np.array([plate_label[0].replace(\"-\", \"\")[4] for plate_label in all_files])\n",
    "y6 = np.array([plate_label[0].replace(\"-\", \"\")[5] for plate_label in all_files])\n",
    "y7 = np.array([plate_label[0].replace(\"-\", \"\")[6] for plate_label in all_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y1, y2, y3, y4, y5, y6, y7 = shuffle(X, y1, y2, y3, y4, y5, y6, y7)\n",
    "categories = np.array(list(\"ABCDEFGHIJKLMNOPRSTUVYZ0123456789\"))\n",
    "onehot_enc = OneHotEncoder(sparse=False)\n",
    "onehot_enc.fit(categories.reshape(-1, 1))\n",
    "\n",
    "y1 = onehot_enc.transform(y1.reshape(-1, 1))\n",
    "y2 = onehot_enc.transform(y2.reshape(-1, 1))\n",
    "y3 = onehot_enc.transform(y3.reshape(-1, 1))\n",
    "y4 = onehot_enc.transform(y4.reshape(-1, 1))\n",
    "y5 = onehot_enc.transform(y5.reshape(-1, 1))\n",
    "y6 = onehot_enc.transform(y6.reshape(-1, 1))\n",
    "y7 = onehot_enc.transform(y7.reshape(-1, 1))\n",
    "\n",
    "X_train, X_test, \\\n",
    "y1_train, y1_test, \\\n",
    "y2_train, y2_test, \\\n",
    "y3_train, y3_test, \\\n",
    "y4_train, y4_test, \\\n",
    "y5_train, y5_test, \\\n",
    "y6_train, y6_test, \\\n",
    "y7_train, y7_test = \\\n",
    "    train_test_split(X, y1, y2, y3, y4, y5, y6, y7, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomGenerator(Sequence):\n",
    "    def __init__(self, image_filenames, labels, batch_size):\n",
    "        self.image_filenames = image_filenames\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return (np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(np.int)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "        batch_y1 = self.labels[0][idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "        batch_y2 = self.labels[1][idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "        batch_y3 = self.labels[2][idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "        batch_y4 = self.labels[3][idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "        batch_y5 = self.labels[4][idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "        batch_y6 = self.labels[5][idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "        batch_y7 = self.labels[6][idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "        \n",
    "        return np.array([cv2.imread(filename) / 255.0\n",
    "                         for filename in batch_x]), \\\n",
    "            [np.array(batch_y1), np.array(batch_y2), np.array(batch_y3), np.array(batch_y4), np.array(batch_y5), np.array(batch_y6), np.array(batch_y7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "training_batch_generator = MyCustomGenerator(X_train, (y1_train, y2_train, y3_train, y4_train, y5_train, y6_train, y7_train), batch_size)\n",
    "test_batch_generator = MyCustomGenerator(X_test, (y1_test, y2_test, y3_test, y4_test, y5_test, y6_test, y7_test), batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 218, 1025, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 216, 1023, 8) 224         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 214, 1021, 8) 584         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 107, 510, 8)  0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 105, 508, 16) 1168        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 103, 506, 16) 2320        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 51, 253, 16)  0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 49, 251, 16)  2320        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 47, 249, 16)  2320        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 23, 124, 16)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 45632)        0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           2920512     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 33)           2145        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 33)           2145        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 33)           2145        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 33)           2145        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 33)           2145        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 33)           2145        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 33)           2145        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,944,463\n",
      "Trainable params: 2,944,463\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "WIDTH = 1025\n",
    "HEIGHT = 218\n",
    "CHANNEL = 3\n",
    "\n",
    "inputs = Input(shape=(HEIGHT, WIDTH, CHANNEL))\n",
    "conv1 = Conv2D(8, kernel_size=3, activation=\"relu\")(inputs)\n",
    "conv1 = Conv2D(8, kernel_size=3, activation=\"relu\")(conv1)\n",
    "conv1 = MaxPooling2D()(conv1)\n",
    "\n",
    "conv2 = Conv2D(16, kernel_size=3, activation=\"relu\")(conv1)\n",
    "conv2 = Conv2D(16, kernel_size=3, activation=\"relu\")(conv2)\n",
    "conv2 = MaxPooling2D()(conv2)\n",
    "\n",
    "conv3 = Conv2D(16, kernel_size=3, activation=\"relu\")(conv2)\n",
    "conv3 = Conv2D(16, kernel_size=3, activation=\"relu\")(conv3)\n",
    "conv3 = MaxPooling2D()(conv3)\n",
    "\n",
    "dense = Flatten()(conv3)\n",
    "\n",
    "dense = Dense(64, activation=\"relu\")(dense)\n",
    "\n",
    "dense_output1 = Dense(33, activation=\"softmax\")(dense)\n",
    "dense_output2 = Dense(33, activation=\"softmax\")(dense)\n",
    "dense_output3 = Dense(33, activation=\"softmax\")(dense)\n",
    "dense_output4 = Dense(33, activation=\"softmax\")(dense)\n",
    "dense_output5 = Dense(33, activation=\"softmax\")(dense)\n",
    "dense_output6 = Dense(33, activation=\"softmax\")(dense)\n",
    "dense_output7 = Dense(33, activation=\"softmax\")(dense)\n",
    "\n",
    "model = Model(inputs=inputs, \\\n",
    "              outputs=[dense_output1, dense_output2, dense_output3, dense_output4, dense_output5, dense_output6, dense_output7])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 1420s 568ms/step - loss: 7.2666 - dense_2_loss: 0.4788 - dense_3_loss: 0.5542 - dense_4_loss: 1.1017 - dense_5_loss: 1.7283 - dense_6_loss: 1.6196 - dense_7_loss: 0.9883 - dense_8_loss: 0.7957 - dense_2_acc: 0.8374 - dense_3_acc: 0.8175 - dense_4_acc: 0.6515 - dense_5_acc: 0.4714 - dense_6_acc: 0.5225 - dense_7_acc: 0.6688 - dense_8_acc: 0.7287\n",
      "Epoch 2/10\n",
      " 965/2500 [==========>...................] - ETA: 12:56 - loss: 2.7108 - dense_2_loss: 0.1053 - dense_3_loss: 0.1457 - dense_4_loss: 0.3315 - dense_5_loss: 0.7293 - dense_6_loss: 0.8223 - dense_7_loss: 0.3935 - dense_8_loss: 0.1833 - dense_2_acc: 0.9659 - dense_3_acc: 0.9502 - dense_4_acc: 0.8876 - dense_5_acc: 0.7547 - dense_6_acc: 0.7371 - dense_7_acc: 0.8753 - dense_8_acc: 0.9449"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(training_batch_generator, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(test_batch_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_hat = onehot_enc.inverse_transform(predictions[0])\n",
    "y2_hat = onehot_enc.inverse_transform(predictions[1])\n",
    "y3_hat = onehot_enc.inverse_transform(predictions[2])\n",
    "y4_hat = onehot_enc.inverse_transform(predictions[3])\n",
    "y5_hat = onehot_enc.inverse_transform(predictions[4])\n",
    "y6_hat = onehot_enc.inverse_transform(predictions[5])\n",
    "y7_hat = onehot_enc.inverse_transform(predictions[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_test = onehot_enc.inverse_transform(y1_test)\n",
    "y2_test = onehot_enc.inverse_transform(y2_test)\n",
    "y3_test = onehot_enc.inverse_transform(y3_test)\n",
    "y4_test = onehot_enc.inverse_transform(y4_test)\n",
    "y5_test = onehot_enc.inverse_transform(y5_test)\n",
    "y6_test = onehot_enc.inverse_transform(y6_test)\n",
    "y7_test = onehot_enc.inverse_transform(y7_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2330\n",
      "           1       1.00      1.00      1.00      2545\n",
      "           2       0.99      1.00      1.00      2567\n",
      "           3       1.00      1.00      1.00      2400\n",
      "           4       1.00      1.00      1.00      2488\n",
      "           5       1.00      1.00      1.00      2434\n",
      "           6       1.00      1.00      1.00      2462\n",
      "           7       1.00      1.00      1.00      2539\n",
      "           8       1.00      0.91      0.95       235\n",
      "\n",
      "    accuracy                           1.00     20000\n",
      "   macro avg       1.00      0.99      0.99     20000\n",
      "weighted avg       1.00      1.00      1.00     20000\n",
      "\n",
      "########################################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1999\n",
      "           1       1.00      1.00      1.00      2021\n",
      "           2       1.00      1.00      1.00      2031\n",
      "           3       1.00      1.00      1.00      2052\n",
      "           4       1.00      1.00      1.00      1979\n",
      "           5       1.00      1.00      1.00      1963\n",
      "           6       1.00      1.00      1.00      1931\n",
      "           7       1.00      1.00      1.00      2027\n",
      "           8       1.00      1.00      1.00      1975\n",
      "           9       1.00      1.00      1.00      2022\n",
      "\n",
      "    accuracy                           1.00     20000\n",
      "   macro avg       1.00      1.00      1.00     20000\n",
      "weighted avg       1.00      1.00      1.00     20000\n",
      "\n",
      "########################################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       1.00      1.00      1.00       905\n",
      "           B       1.00      1.00      1.00       933\n",
      "           C       1.00      1.00      1.00       876\n",
      "           D       1.00      1.00      1.00       846\n",
      "           E       1.00      1.00      1.00       829\n",
      "           F       1.00      1.00      1.00       841\n",
      "           G       1.00      1.00      1.00       897\n",
      "           H       1.00      1.00      1.00       887\n",
      "           I       1.00      1.00      1.00       836\n",
      "           J       1.00      1.00      1.00       897\n",
      "           K       1.00      1.00      1.00       898\n",
      "           L       1.00      1.00      1.00       895\n",
      "           M       1.00      1.00      1.00       847\n",
      "           N       1.00      1.00      1.00       876\n",
      "           O       1.00      1.00      1.00       869\n",
      "           P       1.00      1.00      1.00       846\n",
      "           R       1.00      1.00      1.00       801\n",
      "           S       1.00      1.00      1.00       882\n",
      "           T       1.00      1.00      1.00       862\n",
      "           U       1.00      1.00      1.00       861\n",
      "           V       1.00      1.00      1.00       848\n",
      "           Y       1.00      1.00      1.00       856\n",
      "           Z       1.00      1.00      1.00       912\n",
      "\n",
      "    accuracy                           1.00     20000\n",
      "   macro avg       1.00      1.00      1.00     20000\n",
      "weighted avg       1.00      1.00      1.00     20000\n",
      "\n",
      "########################################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       730\n",
      "           1       1.00      1.00      1.00       648\n",
      "           2       1.00      1.00      1.00       667\n",
      "           3       1.00      1.00      1.00       626\n",
      "           4       1.00      1.00      1.00       651\n",
      "           5       1.00      0.99      0.99       662\n",
      "           6       1.00      1.00      1.00       678\n",
      "           7       1.00      1.00      1.00       716\n",
      "           8       1.00      1.00      1.00       658\n",
      "           9       1.00      1.00      1.00       667\n",
      "           A       0.96      1.00      0.98       572\n",
      "           B       1.00      1.00      1.00       581\n",
      "           C       0.99      1.00      1.00       584\n",
      "           D       1.00      0.99      1.00       606\n",
      "           E       1.00      1.00      1.00       557\n",
      "           F       0.99      1.00      1.00       586\n",
      "           G       1.00      1.00      1.00       559\n",
      "           H       1.00      1.00      1.00       579\n",
      "           I       1.00      0.97      0.98       523\n",
      "           J       1.00      0.98      0.99       588\n",
      "           K       0.99      1.00      1.00       586\n",
      "           L       1.00      0.99      0.99       604\n",
      "           M       1.00      1.00      1.00       576\n",
      "           N       1.00      1.00      1.00       576\n",
      "           O       0.99      1.00      1.00       554\n",
      "           P       1.00      0.99      1.00       589\n",
      "           R       1.00      1.00      1.00       616\n",
      "           S       0.99      1.00      0.99       584\n",
      "           T       1.00      0.99      1.00       532\n",
      "           U       1.00      0.99      1.00       598\n",
      "           V       1.00      1.00      1.00       557\n",
      "           Y       1.00      1.00      1.00       624\n",
      "           Z       1.00      0.99      1.00       566\n",
      "\n",
      "    accuracy                           1.00     20000\n",
      "   macro avg       1.00      1.00      1.00     20000\n",
      "weighted avg       1.00      1.00      1.00     20000\n",
      "\n",
      "########################################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99      1316\n",
      "           1       1.00      1.00      1.00      1297\n",
      "           2       1.00      0.99      1.00      1332\n",
      "           3       0.97      1.00      0.99      1313\n",
      "           4       1.00      0.99      0.99      1258\n",
      "           5       0.99      1.00      1.00      1382\n",
      "           6       0.99      1.00      1.00      1347\n",
      "           7       1.00      1.00      1.00      1336\n",
      "           8       1.00      1.00      1.00      1376\n",
      "           9       1.00      1.00      1.00      1330\n",
      "           A       0.96      0.99      0.97       286\n",
      "           B       0.99      1.00      1.00       297\n",
      "           C       0.99      0.99      0.99       284\n",
      "           D       1.00      0.99      1.00       283\n",
      "           E       1.00      1.00      1.00       297\n",
      "           F       1.00      0.99      0.99       290\n",
      "           G       1.00      1.00      1.00       237\n",
      "           H       1.00      0.99      1.00       297\n",
      "           I       0.98      0.95      0.97       293\n",
      "           J       0.85      1.00      0.92       287\n",
      "           K       0.97      1.00      0.98       287\n",
      "           L       0.99      1.00      1.00       289\n",
      "           M       1.00      0.98      0.99       316\n",
      "           N       1.00      1.00      1.00       268\n",
      "           O       0.99      0.99      0.99       295\n",
      "           P       0.99      1.00      0.99       289\n",
      "           R       1.00      0.98      0.99       301\n",
      "           S       0.99      0.98      0.99       315\n",
      "           T       0.97      1.00      0.98       283\n",
      "           U       1.00      0.93      0.96       302\n",
      "           V       1.00      0.91      0.95       287\n",
      "           Y       0.99      0.99      0.99       296\n",
      "           Z       0.99      0.99      0.99       334\n",
      "\n",
      "    accuracy                           0.99     20000\n",
      "   macro avg       0.99      0.99      0.99     20000\n",
      "weighted avg       0.99      0.99      0.99     20000\n",
      "\n",
      "########################################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      2005\n",
      "           1       1.00      0.98      0.99      1935\n",
      "           2       0.99      0.99      0.99      2031\n",
      "           3       0.98      0.99      0.99      1990\n",
      "           4       0.99      0.99      0.99      2052\n",
      "           5       0.99      0.98      0.98      1997\n",
      "           6       0.99      0.98      0.98      2050\n",
      "           7       0.98      0.99      0.99      2015\n",
      "           8       0.98      0.99      0.98      2020\n",
      "           9       0.98      0.99      0.99      1905\n",
      "\n",
      "    accuracy                           0.99     20000\n",
      "   macro avg       0.99      0.99      0.99     20000\n",
      "weighted avg       0.99      0.99      0.99     20000\n",
      "\n",
      "########################################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      1951\n",
      "           1       1.00      0.96      0.98      1973\n",
      "           2       1.00      1.00      1.00      2020\n",
      "           3       0.95      1.00      0.97      2027\n",
      "           4       1.00      0.99      0.99      2085\n",
      "           5       1.00      0.99      1.00      2044\n",
      "           6       1.00      1.00      1.00      1956\n",
      "           7       1.00      1.00      1.00      1973\n",
      "           8       1.00      0.99      1.00      1978\n",
      "           9       1.00      1.00      1.00      1993\n",
      "\n",
      "    accuracy                           0.99     20000\n",
      "   macro avg       0.99      0.99      0.99     20000\n",
      "weighted avg       0.99      0.99      0.99     20000\n",
      "\n",
      "########################################\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y1_test, y1_hat))\n",
    "print(\"#\" * 40)\n",
    "print(classification_report(y2_test, y2_hat))\n",
    "print(\"#\" * 40)\n",
    "print(classification_report(y3_test, y3_hat))\n",
    "print(\"#\" * 40)\n",
    "print(classification_report(y4_test, y4_hat))\n",
    "print(\"#\" * 40)\n",
    "print(classification_report(y5_test, y5_hat))\n",
    "print(\"#\" * 40)\n",
    "print(classification_report(y6_test, y6_hat))\n",
    "print(\"#\" * 40)\n",
    "print(classification_report(y7_test, y7_hat))\n",
    "print(\"#\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(218, 1025, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_image = next(iter(test_batch_generator))\n",
    "print(test_image[0][1].shape)\n",
    "plt.imshow(test_image[0][1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(test_image[0][1].reshape(1, 218, 1025, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04IUT15"
     ]
    }
   ],
   "source": [
    "for ch in prediction:\n",
    "    print(onehot_enc.inverse_transform(ch)[0][0], end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
